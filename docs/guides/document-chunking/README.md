# ðŸ§  Insight IngeniousÂ â€“ DocumentÂ Chunking

A robust, extensible service **and** CLI for splitting documents into precise, contextâ€‘aware chunksâ€”perfect for Retrievalâ€‘Augmented Generation (RAG) pipelines.

---

## Overview

The **`chunk`** module provides the core textâ€‘splitting capabilities within the Insightâ€¯Ingenious framework. It transforms large source documents (Text, Markdown, JSON, JSONL) into smaller segments that balance semantic coherence with Large Language Model token limits.

**Ideal for:**

* Preparing data for vector databases and embedding models.
* Consistent, tokenâ€‘aware splitting across mixed document types.
* Bidirectional context overlap between chunks to boost retrieval quality.

---

## Features

* âœ¨ **Multiple Strategies**Â â€“ recursive, markdown, token, and semantic splitting.
* ðŸ“ **Precise Budgeting**Â â€“ configure `chunk_size` & `chunk_overlap` in tokens (via *tiktoken*) **or** characters.
* ðŸ”— **Bidirectional Overlap**Â â€“ overlap before *and* after each chunk for maximum context preservation.
* ðŸŒ **Unicode Safe**Â â€“ token strategy respects grapheme boundaries, protecting complex characters & emojis.
* ðŸ§  **Semantic Splitting**Â â€“ OpenAIâ€¯/â€¯Azureâ€¯OpenAI embeddings find natural semantic breaks.
* âš¡ **Efficient Loading**Â â€“ streams large JSON via *ijson* to minimise memory.
* ðŸ†” **Stable IDs**Â â€“ deterministic, globallyâ€‘unique chunk IDs with configurable path encoding.

---

## Installation

The chunking capabilities are an **optional extra**.

```bash
# Install the core ingenious package with the chunking extra
uv pip install -e ".[chunk]"
```

> **Note**Â Â Semantic splitting requires access to OpenAI or Azure OpenAI embeddings.

---

## QuickÂ StartÂ (CLI)

The primary entryâ€‘point is `ingen chunk run`.

### BasicÂ RecursiveÂ Splitting

Split a text file into 512â€‘token chunks with a 64â€‘token overlap:

```bash
ingen chunk run my_document.txt \
  --strategy recursive \
  --chunk-size 512 \
  --chunk-overlap 64 \
  --output chunks.jsonl
```

### ProcessingÂ JSONLÂ Input

Chunk each record from a JSONâ€¯Lines file (e.g. output from *ingen documentâ€‘processing*):

```bash
ingen chunk run extracted_pages.jsonl -o chunks.jsonl
```

### SemanticÂ Splitting *(requires `OPENAI_API_KEY`)*

```bash
ingen chunk run research_paper.md --strategy semantic -o semantic_chunks.jsonl
```

---

## PythonÂ API

```python
from ingenious.chunk import ChunkConfig, build_splitter

# 1 Â· Define configuration
config = ChunkConfig(
    strategy="token",
    chunk_size=256,
    chunk_overlap=32,
    overlap_unit="tokens"
)

# 2 Â· Build the splitter instance
splitter = build_splitter(config)

# 3 Â· Split text
text = "Your long document content goes here..."
chunks = splitter.split_text(text)

print(f"Generated {len(chunks)} chunks.")
# print(chunks[0])
```

---

## ConfigurationÂ &Â Strategies

Behaviour is controlled via CLI flags that map 1â€‘toâ€‘1 with the `ChunkConfig` model.

### AvailableÂ Strategies

| Strategy    | Description                                                        | KeyÂ Configuration                                                        |
| ----------- | ------------------------------------------------------------------ | ------------------------------------------------------------------------ |
| `recursive` | Hierarchical splits (paragraphâ†’sentenceâ†’word). Fast and versatile. | `--chunk-size`, `--chunk-overlap`, `--separators`                        |
| `markdown`  | Aware of Markdown structure (headers, lists).                      | `--chunk-size`, `--chunk-overlap`                                        |
| `token`     | Splits on token boundaries, Unicodeâ€‘safe.                          | `--chunk-size`, `--chunk-overlap`, `--encoding-name`                     |
| `semantic`  | Uses embeddings to split at semantic breaks.                       | `--embed-model`, `--azure-deployment`, `--semantic-threshold-percentile` |

### CoreÂ Options

| Flag              | Description                                      | Default       |
| ----------------- | ------------------------------------------------ | ------------- |
| `--strategy`      | Splitting algorithm.                             | `recursive`   |
| `--chunk-size`    | Max size of each chunk (tokens/chars).           | `1024`        |
| `--chunk-overlap` | Overlap between adjacent chunks.                 | `128`         |
| `--overlap-unit`  | Unit for size/overlap: `tokens` or `characters`. | `tokens`      |
| `--encoding-name` | *tiktoken* encoding for token counting.          | `cl100k_base` |

---

## InputÂ FileÂ Contract

| Format                     | Handling                                                                         |
| -------------------------- | -------------------------------------------------------------------------------- |
| `.txt`, `.md`, `.markdown` | Entire file treated as one document.                                             |
| `.json`                    | Object or array; each object must include `text`, `page_content`, **or** `body`. |
| `.jsonl`, `.ndjson`        | One JSON object per line with the keys above.                                    |

---

## AdvancedÂ Â·Â Stable ChunkÂ IDs

CLI generates deterministic IDs: `<prefix>#p<page>.<pos>-<hash>` where `<prefix>` is set by `--id-path-mode`.

* **`rel`** *(default)*Â â€“ path relative to CWD (or `--id-base`). Falls back to hashed absâ€‘path when outside base.
* **`hash`**Â â€“ always truncated SHAâ€‘256 of absâ€‘path. Good for privacy / crossâ€‘machine stability.
* **`abs`**Â â€“ absolute file system path (may leak info). Requires `--force-abs-path`.

```bash
# Example: use hashing for the ID prefix
ingen chunk run my_document.txt --id-path-mode hash
```

---

## DevelopmentÂ &Â Testing

```bash
# Install testing dependencies
a uv pip install -e ".[chunk,test]"

# Run the test suite
pytest ingenious/chunk/tests
```

---

**HappyÂ Chunking!** ðŸš€
